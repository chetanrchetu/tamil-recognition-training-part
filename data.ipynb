{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Seperation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN=r'D:\\major_project\\megha\\project-1\\processed\\train'\n",
    "TEST=r'D:\\major_project\\megha\\project-1\\processed\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "files_path=pd.DataFrame(columns=['Image','label'])\n",
    "def get_files_from_path(directory):\n",
    "    \n",
    "    for i in os.listdir(directory):\n",
    "    \n",
    "        for j in os.listdir(f\"{directory}\\\\{i}\"):\n",
    "            \n",
    "\n",
    "            path=os.path.join('processed','train',i,j)\n",
    "\n",
    "            number=len(files_path)\n",
    "            files_path.at[number,'Image']=path\n",
    "            files_path.at[number,'label']=int(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "if os.path.exists(r'D:\\major_project\\megha\\project-1\\processed\\train\\train_images.csv'):\n",
    "    train=pd.read_csv(r'D:\\major_project\\megha\\project-1\\processed\\train\\train_images.csv')\n",
    "else:\n",
    "    \n",
    "    get_files_from_path(TRAIN)\n",
    "    files_path.to_csv(r'D:\\major_project\\megha\\project-1\\processed\\train\\train_images.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "files_path=pd.DataFrame(columns=['Image','label'])\n",
    "def get_files_from_path(directory):\n",
    "    \n",
    "    for i in os.listdir(directory):\n",
    "    \n",
    "        for j in os.listdir(f\"{directory}\\\\{i}\"):\n",
    "            \n",
    "\n",
    "            path=os.path.join('processed','test',i,j)\n",
    "\n",
    "            number=len(files_path)\n",
    "            files_path.at[number,'Image']=path\n",
    "            files_path.at[number,'label']=int(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "if os.path.exists(r'D:\\major_project\\megha\\project-1\\processed\\test\\test_images.csv'):\n",
    "    test=pd.read_csv(r'D:\\major_project\\megha\\project-1\\processed\\test\\test_images.csv')\n",
    "else:\n",
    "    \n",
    "    get_files_from_path(TRAIN)\n",
    "    files_path.to_csv(r'D:\\major_project\\megha\\project-1\\processed\\test\\test_images.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>processed\\train\\0\\000u100t01.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>processed\\train\\0\\000u100t02.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>processed\\train\\0\\000u103t01.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>processed\\train\\0\\000u103t02.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>processed\\train\\0\\000u104t01.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Image  label\n",
       "0  processed\\train\\0\\000u100t01.tiff      0\n",
       "1  processed\\train\\0\\000u100t02.tiff      0\n",
       "2  processed\\train\\0\\000u103t01.tiff      0\n",
       "3  processed\\train\\0\\000u103t02.tiff      0\n",
       "4  processed\\train\\0\\000u104t01.tiff      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image loading part and apply preprocesising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def preprocess(image_path):\n",
    "\n",
    "    numpy_img=cv2.imread(image_path)\n",
    "    # Convert NumPy array to PIL image\n",
    "    img = Image.fromarray(numpy_img)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    converted = img.convert(\"L\")\n",
    "\n",
    "    # Invert colors\n",
    "    inverted = ImageOps.invert(converted)\n",
    "\n",
    "    # Apply maximum filter\n",
    "    thick = inverted.filter(ImageFilter.MaxFilter(5))\n",
    "\n",
    "    # Calculate resizing ratio (adjusting for smaller size)\n",
    "    ratio = 32.0 / max(thick.size)\n",
    "\n",
    "    # Resize image\n",
    "    new_size = tuple([int(round(x*ratio)) for x in thick.size])\n",
    "    res = thick.resize(new_size, Image.LANCZOS)\n",
    "    \n",
    "    # Convert resized image back to NumPy array\n",
    "    arr = np.asarray(res)\n",
    "\n",
    "    # Calculate center of mass\n",
    "    com = ndimage.center_of_mass(arr)\n",
    "\n",
    "    # Create blank image\n",
    "    result = np.zeros((64, 64), dtype=np.uint8)\n",
    "\n",
    "    # Calculate paste box coordinates\n",
    "    box = (int(round(32.0 - com[1])), int(round(32.0 - com[0])))\n",
    "\n",
    "    # Paste resized image onto blank image\n",
    "    result[box[1]:box[1]+arr.shape[0], box[0]:box[0]+arr.shape[1]] = arr\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50683, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffled=train.sample(train.shape[0]).reset_index().iloc[:,1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "\n",
    "for index,row in train_shuffled.iterrows():\n",
    "    image_path=row[0]\n",
    "    label=row[1]\n",
    "\n",
    "    pre_img=preprocess(image_path)\n",
    "    \n",
    "\n",
    "    X.append(pre_img)\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X).reshape(-1,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle_out=open(r'D:\\major_project\\megha\\project-1\\data_final\\train\\X.pickle','wb')\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "pickle_out=open(r'D:\\major_project\\megha\\project-1\\data_final\\train\\y.pickle','wb')\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26926, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shuffled=test.sample(test.shape[0]).reset_index().iloc[:,1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "y_test=[]\n",
    "\n",
    "print_label=None\n",
    "for index,row in test_shuffled.iterrows():\n",
    "    \n",
    "    image_path=row[0]\n",
    "    label=row[1]\n",
    "\n",
    "    pre_img=preprocess(image_path)\n",
    "    \n",
    "\n",
    "    X_test.append(pre_img)\n",
    "    y_test.append(label)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(X_test).reshape(-1,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out=open(r'D:\\major_project\\megha\\project-1\\data_final\\test\\X_test.pickle','wb')\n",
    "pickle.dump(X_test,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "pickle_out=open(r'D:\\major_project\\megha\\project-1\\data_final\\test\\y_test.pickle','wb')\n",
    "pickle.dump(y_test,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
